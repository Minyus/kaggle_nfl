pytorch_model:
  =: torch.nn.Sequential
  _:
    - =: pipelinex.ModuleProd
      _:
        - =: torch.nn.Sequential
          _:
            - {=: pipelinex.TensorSlice, start: 18}
            - {=: pipelinex.TensorSqueeze, dim: 1}
            - {=: pipelinex.TensorSlice, start: 1, end: 2}
            - {=: pipelinex.TensorSqueeze, dim: 1}
            - {=: pipelinex.TensorSlice, end: 1}
            - {=: pipelinex.TensorSqueeze, dim: 1}
            # -> [N]  # YardsToGoalP10Val
            - {=: pipelinex.StepBinary, size: 100, desc: True}
            # -> [N, 100]  # YardsToGoal mask
        - =: torch.nn.Sequential
          _:
            - =: pipelinex.ModuleSum
              _:
                - =: torch.nn.Sequential
                  _:
                    - {=: pipelinex.TensorSlice, start: 18}
                    - {=: pipelinex.TensorSqueeze, dim: 1}
                    - {=: pipelinex.TensorSlice, start: 0, end: 1}
                    - {=: pipelinex.TensorFlatten, _: }
                    - {=: pipelinex.TensorSlice, start: 0, end: 50}
                    # -> [N, 50]  # - Base Probas
                - =: torch.nn.Sequential
                  _:
                    - =: pipelinex.ModuleConcat
                      _:
                        - =: torch.nn.Sequential
                          _:
                            - {=: pipelinex.TensorSlice, start: 18}
                            - {=: pipelinex.TensorSqueeze, dim: 1}
                            - {=: pipelinex.TensorSlice, start: 1, end: 6}
                            - {=: pipelinex.TensorFlatten, _: }
                            - {=: pipelinex.TensorSlice, start: 1}
                            - {=: torch.nn.Linear, in_features: 269, out_features: 200}
                            - {=: torch.nn.CELU, alpha: 1.0}
                            - {=: torch.nn.Linear, in_features: 200, out_features: 200}
                            - {=: torch.nn.CELU, alpha: 1.0}
        #                    - =: pipelinex.ModuleConcat
        #                      _:
        #                      - =: torch.nn.Sequential
        #                        _:
        #                          - {=: pipelinex.TensorSlice, start: 0, end: 1}
        #                          - {=: pipelinex.TensorFlatten, _: }
        #                          - {=: torch.nn.Linear, in_features: 54, out_features: 25}
        #                          - {=: torch.nn.CELU, alpha: 1.0}
        #                      - =: torch.nn.Sequential
        #                        _:
        #                          - {=: pipelinex.TensorSlice, start: 1, end: 2}
        #                          - {=: pipelinex.TensorFlatten, _: }
        #                          - {=: torch.nn.Linear, in_features: 54, out_features: 15}
        #                          - {=: torch.nn.Sigmoid, _: }
        #                      - =: torch.nn.Sequential
        #                        _:
        #                          - {=: pipelinex.TensorSlice, start: 2, end: 3}
        #                          - {=: pipelinex.TensorFlatten, _: }
        #                          - {=: torch.nn.Linear, in_features: 54, out_features: 15}
        #                          - {=: torch.nn.Sigmoid, _: }
        #                      - =: torch.nn.Sequential
        #                        _:
        #                          - {=: pipelinex.TensorSlice, start: 3, end: 4}
        #                          - {=: pipelinex.TensorFlatten, _: }
        #                          - {=: torch.nn.Linear, in_features: 54, out_features: 15}
        #                          - {=: torch.nn.CELU, alpha: 1.0}
        #                      - =: torch.nn.Sequential
        #                        _:
        #                          - {=: pipelinex.TensorSlice, start: 4, end: 5}
        #                          - {=: pipelinex.TensorFlatten, _: }
        #                          - {=: torch.nn.Linear, in_features: 54, out_features: 15}
        #                          - {=: torch.nn.CELU, alpha: 1.0}
        #                      - =: torch.nn.Sequential
        #                        _:
        #                          - {=: pipelinex.TensorSlice, start: 5, end: 6}
        #                          - {=: pipelinex.TensorFlatten, _: }
        #                          - {=: torch.nn.Linear, in_features: 54, out_features: 5}
        #                          - {=: torch.nn.CELU, alpha: 1.0}
        #                      - =: torch.nn.Sequential
        #                        _:
        #                          - {=: pipelinex.TensorSlice, start: 6, end: 7}
        #                          - {=: pipelinex.TensorFlatten, _: }
        #                          - {=: torch.nn.Linear, in_features: 54, out_features: 5}
        #                          - {=: torch.nn.CELU, alpha: 1.0}
        #                      - =: torch.nn.Sequential
        #                        _:
        #                          - {=: pipelinex.TensorSlice, start: 7, end: 8}
        #                          - {=: pipelinex.TensorFlatten, _: }
        #                          - {=: torch.nn.Linear, in_features: 54, out_features: 5}
        #                          - {=: torch.nn.CELU, alpha: 1.0}
                        - =: torch.nn.Sequential
                          _:
                            - {=: pipelinex.TensorSlice, end: 18}
                            - {=: pipelinex.TensorGlobalAvgPool2d, keepdim: False}
                            - {=: torch.nn.Linear, in_features: 18, out_features: 15}
                            - {=: torch.nn.CELU, alpha: 1.0}
                        - =: torch.nn.Sequential
                          _:
                            - {=: pipelinex.TensorSlice, end: 18}
                            - {=: pipelinex.TensorGlobalMaxPool2d, keepdim: False}
                            - {=: torch.nn.Linear, in_features: 18, out_features: 15}
                            - {=: torch.nn.Sigmoid, _: }
                        - =: torch.nn.Sequential
                          _:
                            - {=: pipelinex.TensorSlice, end: 18}
                            - {=: pipelinex.TensorGlobalMinPool2d, keepdim: False}
                            - {=: torch.nn.Linear, in_features: 18, out_features: 15}
                            - {=: torch.nn.Sigmoid, _: }
                        - =: torch.nn.Sequential
                          _:
                            - {=: pipelinex.TensorSlice, end: 18}
                            - {=: pipelinex.TensorGlobalRangePool2d, keepdim: False}
                            - {=: torch.nn.Linear, in_features: 18, out_features: 15}
                            - {=: torch.nn.Sigmoid, _: }
                        - =: torch.nn.Sequential
                          _:
                            - {=: pipelinex.TensorSlice, end: 18}
                            - =: pipelinex.ModuleConcat
                              _:
                #                - {=: kaggle_nfl.kaggle_nfl.GaussianBlur2d, kernel_size: "(15, 15)", sigma: "(5.0, 5.0)"}
                                - {=: pipelinex.TensorConv2d, in_channels: 18, out_channels: 10, kernel_size: [3, 3]}
                                - {=: pipelinex.TensorConv2d, in_channels: 18, out_channels: 10, kernel_size: [7, 7]}
                                - {=: pipelinex.TensorConv2d, in_channels: 18, out_channels: 10, kernel_size: [3, 9]}
                            - {=: torch.nn.CELU, alpha: 1.0}
                            - =: pipelinex.ModuleConcat
                              _:
                                - {=: pipelinex.TensorAvgPool2d, stride: [1, 2], kernel_size: [3, 3]}
                                - {=: pipelinex.TensorConv2d, stride: [1, 2], in_channels: 30, out_channels: 10, kernel_size: [3, 3]}
                                - {=: pipelinex.TensorConv2d, stride: [1, 2], in_channels: 30, out_channels: 10, kernel_size: [7, 7]}
                                - {=: pipelinex.TensorConv2d, stride: [1, 2], in_channels: 30, out_channels: 10, kernel_size: [3, 9]}
                            - {=: torch.nn.CELU, alpha: 1.0}
                #            - =: pipelinex.ModuleConcat
                #              _:
                #                - {=: pipelinex.TensorConv2d, in_channels: 60, out_channels: 60, kernel_size: [1, 1]}
                #                - {=: pipelinex.TensorConv2d, in_channels: 60, out_channels: 20, kernel_size: [3, 3]}
                #                - {=: pipelinex.TensorConv2d, in_channels: 60, out_channels: 20, kernel_size: [7, 7]}
                #                - {=: pipelinex.TensorConv2d, in_channels: 60, out_channels: 20, kernel_size: [5, 15]}
                #            - {=: torch.nn.CELU, alpha: 1.0}
                            - =: pipelinex.ModuleConcat
                              _:
                                - {=: pipelinex.TensorAvgPool2d, stride: [1, 2], kernel_size: [3, 3]}
                                - {=: pipelinex.TensorConv2d, stride: [1, 2], in_channels: 60, out_channels: 20, kernel_size: [3, 3]}
                                - {=: pipelinex.TensorConv2d, stride: [1, 2], in_channels: 60, out_channels: 20, kernel_size: [7, 7]}
                                - {=: pipelinex.TensorConv2d, stride: [1, 2], in_channels: 60, out_channels: 20, kernel_size: [3, 9]}
                              # -> [N, 120, 30, 14]
                            - {=: torch.nn.CELU, alpha: 1.0}
                            - =: pipelinex.ModuleConcat
                              _:
                                - =: torch.nn.Sequential
                                  _:
                                    - {=: torch.nn.AvgPool2d, stride: [1, 2], kernel_size: [3, 14]}
                                    # -> [N, 120, 28, 1]
                                    - {=: pipelinex.TensorConv2d, in_channels: 120, out_channels: 20, kernel_size: [1, 1]}
                                    - {=: pipelinex.TensorFlatten, _: }
                                    - {=: torch.nn.CELU, _: }
                                - =: torch.nn.Sequential
                                  _:
                                    - {=: torch.nn.MaxPool2d, stride: [1, 2], kernel_size: [3, 14]}
                                    # -> [N, 120, 28, 1]
                                    - {=: pipelinex.TensorConv2d, in_channels: 120, out_channels: 20, kernel_size: [1, 1]}
                                    - {=: pipelinex.TensorFlatten, _: }
                                    - {=: torch.nn.CELU, _: }
                    - {=: torch.nn.Linear, in_features: 1380, out_features: 50}
                    - {=: torch.nn.Tanhshrink, _: }
            - {=: pipelinex.TensorNearestPad, lower: 0, upper: 50}
    - {=: torch.nn.ConstantPad1d, padding: [89, 10], value: 0.0}  # 199 = 89 + 100 + 10
#    - {=: torch.nn.Softmax, dim: 1}
    - {=: torch.nn.ReLU, _: }
    - {=: pipelinex.TensorProba, dim: 1}
    - {=: pipelinex.TensorCumsum, dim: 1}
    - {=: pipelinex.TensorClamp, min: 0.0, max: 1.0}

augmentation:
  horizontal_flip_proba: 0
  horizontal_shift_std: 1.0
  vertical_shift_std: 0.1

tta: 0

train_batch_size: 32

train_params:
  epochs: 12  # number of epochs to train
  time_limit: 12000
  model_checkpoint_params:
    dirname: ../checkpoint
    filename_prefix: "%Y-%m-%dT%H-%M-%S"
    offset_hours: 8
    n_saved: 12
    atomic: True
    require_empty: True
    create_dir: True
    save_as_state_dict: False
  early_stopping_params:
    metric: crps
    minimize: True
    patience: 1000
  scheduler:
    =: ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler
#    =: ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler
  scheduler_params:
    param_name: lr
    start_value:
      =: operator.mul
      _:
        - 0.000_001
        - =: train_batch_size
    end_value:
      =: operator.mul
      _:
        - 0.000_01
        - =: train_batch_size
    cycle_epochs: 2  # cycle_size: int(cycle_epochs * len(train_loader))
    cycle_mult: 1.0
    start_value_mult: 1.0
    end_value_mult: 1.0
    save_history: False
  optimizer:
    =: torch.optim.Adam
#  optimizer:
#    =: torch.optim.SGD
  optimizer_params:
    weight_decay:
      =: operator.truediv
      _:
        - 0.001
        - =: train_batch_size
  loss_fn:
    =: kaggle_nfl.kaggle_nfl.NflCrpsLossFunc
    min: -10
    max: 19
#    desc_penalty: 10.0
  evaluation_metrics:
    crps:
      =: ignite.metrics.Loss
      loss_fn:
        =: kaggle_nfl.kaggle_nfl.nfl_crps_loss
#    l1crps:
#      =: ignite.metrics.Loss
#      loss_fn:
#        =: kaggle_nfl.kaggle_nfl.nfl_l1crps_loss
#  train_dataset_size_limit: 128
#  val_dataset_size_limit: 128
  train_data_loader_params:
    batch_size:
      =: train_batch_size
    num_workers: 1
  val_data_loader_params:
    batch_size:
     =: train_batch_size
    num_workers: 1
  evaluate_train_data: COMPLETED
  evaluate_val_data: EPOCH_COMPLETED
  progress_update: True
  seed: 0  #

#q_transformer:
#  =: pipelinex.DfQuantileTransformer
#  n_quantiles: 1000
#  output_distribution: normal
#  subsample: 100000
#  random_state: 42
#  =: pipelinex.DfStandardScaler
#  with_mean: False
#  with_std: True
#  zero_to_zero: FalseQ
#  cols:
#    - _A
#    - _S_X
#    - _S_Y
#    - X_Defense_Max
#    - X_RR_Defense_Max
#    - Y_RR_Defense_Max
#    - X_Offense_Max
#    - X_RR_Offense_Max
#    - Y_RR_Offense_Max
#    - X_Defense_Min
#    - X_RR_Defense_Min
#    - Y_RR_Defense_Min
#    - X_Offense_Min
#    - X_RR_Offense_Min
#    - Y_RR_Offense_Min
#    - X_Defense_Mean
#    - X_RR_Defense_Mean
#    - Y_RR_Defense_Mean
#    - X_Offense_Mean
#    - X_RR_Offense_Mean
#    - Y_RR_Offense_Mean
#    - X_RR_Defense_Stdev
#    - Y_RR_Defense_Stdev
#    - X_RR_Offense_Stdev
#    - Y_RR_Offense_Stdev
#    - X_Rusher
#    - Y_Rusher


RUN_CONFIG:
  pipeline_name: __default__
  only_missing: True
  runner: SequentialRunner # None
  tags: # None
  node_names: # None
  from_nodes: # None
  to_nodes: # None
  from_inputs: # None
  load_versions: # None

MLFLOW_LOGGING_CONFIG:
  offset_hours: 8
  logging_artifacts:  # None

PIPELINES:
  __default__:
    =: pipelinex.FlexiblePipeline
    parameters_in_inputs: False
    module: kaggle_nfl.kaggle_nfl
    decorator: pipelinex.log_time
    nodes:

      - inputs: train
        outputs: df_020

      - inputs: df_020
        func:
          - preprocess
        outputs: df_030

#      - inputs: df_030
#        func:
#          =: pipelinex.df_sample
#          frac: 0.5
#          random_state: 191024
#          col_sample: PlayId
#          col_assign: Validation
#        outputs: df_040

      - inputs: df_030
        func:
          - =: pipelinex.df_head
            groupby: Season
            n: 22
        outputs: df_031_head

      - inputs: df_030
        func:
          - =: pipelinex.df_query
            expr: "TimeHandoff < '2018-11-30T08:00:00'"
        outputs: df_031_train

      - inputs: df_030
        func:
          - =: pipelinex.df_query
            expr: "'2018-11-30T08:00:00' <= TimeHandoff"
        outputs: df_031_val

      - inputs:
          - df_031_train
          - df_031_val
        func:
          =: pipelinex.df_concat
          new_col_name: Validation
          new_col_values: [0, 1]
        outputs: df_040

      - inputs: [df_040, parameters]
        func: generate_datasets
        outputs:
          - train_dataset
          - val_dataset
          - base_probas

      - inputs: parameters
        func:
          =: pass_func
          arg:
            =: pytorch_model
        outputs: initial_model

      - inputs:
          - initial_model
          - train_dataset
          - val_dataset
        func:
          =: pipelinex.NetworkTrain
          train_params:
            =: train_params
          mlflow_logging: True
        outputs: pytorch_model

#      - inputs: [pytorch_model, base_probas, transformer, parameters]
#        func: infer
#        outputs: infered_first_iter

      - inputs:
          - val_dataset
          - pytorch_model
          - parameters
        func: final_validation
        outputs: loss_df

      - inputs: df_020
        outputs: describe

      - inputs: df_020
        func:
          =: pipelinex.df_query
          expr: 'Season == 2017'
        outputs: describe_s2017

      - inputs: df_020
        func:
          =: pipelinex.df_query
          expr: 'Season == 2018'
        outputs: describe_s2018

      - inputs: df_020
        func:
          - =: pipelinex.df_query
            expr: 'NflId == NflIdRusher'
        outputs: rusher_df_raw

      - inputs: df_030
        func:
          =: pipelinex.df_query
          expr: 'Season == 2017'
        outputs: describe_prep_s2017

      - inputs: df_030
        func:
          =: pipelinex.df_query
          expr: 'Season == 2018'
        outputs: describe_prep_s2018

      - inputs: df_030
        func:
          - =: pipelinex.df_query
            expr: 'PlayerCategory == 2'
        outputs: rusher_df

      - inputs: rusher_df
        func:
          - =: pipelinex.df_query
            expr: 'Season == 2017'
        outputs: rusher_2017_describe

      - inputs: rusher_df
        func:
          - =: pipelinex.df_query
            expr: 'Season == 2018'
        outputs: rusher_2018_describe

#      - inputs: play_df
#        func:
#          =: pipelinex.df_drop
#          columns: TimeHandoff
#        outputs: pairplot

#      - inputs: parameters
#        func: get_test_df
#        outputs: test_df
#
#      - inputs:
#          - train
#          - test_df
#        func:
#          =: pipelinex.df_concat
#          _:
#        outputs: eda_df
#
#      - inputs: eda_df
#        func:
#          - =: pipelinex.df_filter
#            items:
#              - GameId
#              - PlayId
#              - X
#              - Y
#              - S
#              - A
#              - Dis
#              - Dir
#              - Season
#              - YardLine
#              - Quarter
#              - PossessionTeam
#              - Down
#              - Distance
#              - FieldPosition
#              - PlayDirection
#              - Yards
#              - Week
#        outputs: df_020_filtered
#